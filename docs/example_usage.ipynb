{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(str(Path().absolute().parent / \"src\"))\n",
    "\n",
    "\n",
    "from brainrnaseq_specificity import (\n",
    "    create_enrichment_dataframe,\n",
    "    map_hgnc_ids,\n",
    "    process_hgnc_data,\n",
    ")\n",
    "from config import MISSING_FASTA_SEQUENCES, hgnc_ids, high_fractions, low_fractions\n",
    "from deeptmhmm_localization import (\n",
    "    get_localization_data,\n",
    "    identify_localization,\n",
    "    parse_gz_file,\n",
    ")\n",
    "from gtex_specificity import gtex_specificity\n",
    "from identify_targets import (\n",
    "    extract_sample_npx,\n",
    "    generate_protein_dataframe,\n",
    "    identify_targets,\n",
    ")\n",
    "from olink_fractionation import analyze_fractionation\n",
    "from raw_data_preprocessing import (\n",
    "    clean_up_raw_data,\n",
    "    find_ratio,\n",
    "    plot_protein_fractionation,\n",
    ")\n",
    "from specificity_functions import calculate_enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data and output directories relative to notebook\n",
    "data_dir = Path().absolute().parent / \"data\"\n",
    "output_dir = Path().absolute().parent / \"outputs\"\n",
    "\n",
    "# Define paths relative to those directories\n",
    "assay_list_path = data_dir / \"231220_ht_panel_assay_list.xlsx\"\n",
    "brain_rna_seq_raw_path = data_dir / \"240411_brain_rna_seq_raw.csv\"\n",
    "output_directory = output_dir / \"ht_output\"\n",
    "plate_layout_path = data_dir / \"231204_Walt_Olink_HT_Plate.xlsx\"\n",
    "raw_data = data_dir / \"240214_Walt_Olink_HT_Raw.parquet\"\n",
    "uniprot_fasta_database = data_dir / \"uniprot_fasta_database.gz\"\n",
    "gtex_path = data_dir / \"GTEx_Analysis_v10_RNASeQCv2.4.2_gene_median_tpm.gct.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tidy dataframe from the raw data file.\n",
    "tidy_data = clean_up_raw_data(raw_data, plate_layout_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SI Table 4\n",
    "\n",
    "# Load and process the Brain RNA-Seq data\n",
    "brain_rna_seq = pd.read_csv(brain_rna_seq_raw_path)\n",
    "hgnc_uniprot_mapping_data = process_hgnc_data(hgnc_ids)\n",
    "brain_rna_seq = (\n",
    "    brain_rna_seq.merge(\n",
    "        hgnc_uniprot_mapping_data, left_on=\"id\", right_on=\"hgnc_id\", how=\"inner\"\n",
    "    )\n",
    "    .dropna(subset=[\"uniprot_ids\"])\n",
    "    .drop_duplicates(subset=[\"uniprot_ids\"])\n",
    ")\n",
    "brain_rna_seq.set_index(\n",
    "    [\"uniprot_ids\", \"symbol\", \"name\", \"alias_symbol\", \"alias_name\"], inplace=True\n",
    ")\n",
    "expression_df = create_enrichment_dataframe(brain_rna_seq)\n",
    "\n",
    "# Calculate tau scores and filter by cutoff\n",
    "tau_score_cutoff = 0.25\n",
    "enrichment_values = expression_df.apply(\n",
    "    lambda row: calculate_enrichment(row, \"tau\"), axis=1\n",
    ")\n",
    "high_tau_score = enrichment_values[enrichment_values < tau_score_cutoff]\n",
    "\n",
    "# Identify proteins with the SEC fractionation pattern indicative of EV association\n",
    "fractionation_uniprot_ids = analyze_fractionation(\n",
    "    tidy_data,\n",
    "    high_fractions,\n",
    "    low_fractions,\n",
    "    sample_health=\"healthy\",\n",
    "    mean_median_individual=\"individual_median\",\n",
    ")\n",
    "\n",
    "# Identify protein localizations\n",
    "fasta_sequences = parse_gz_file(uniprot_fasta_database)\n",
    "fasta_sequences.update(MISSING_FASTA_SEQUENCES)\n",
    "assays = pd.read_excel(assay_list_path)\n",
    "localization_ids = get_localization_data(\n",
    "    assays, fasta_sequences, [\"TMhelix\", \"internal\", \"external\"], output_directory\n",
    ")\n",
    "\n",
    "# Generate categorized protein dataframes\n",
    "localization_labels = {\n",
    "    \"internal\": \"internal\",\n",
    "    \"TMhelix\": \"transmembrane\",\n",
    "    \"external\": \"external\",\n",
    "}\n",
    "protein_dataframes = [\n",
    "    generate_protein_dataframe(\n",
    "        low_tau_proteins,\n",
    "        fractionation_uniprot_ids,\n",
    "        list(localization_ids[loc_type]),\n",
    "        label,\n",
    "        tidy_data,\n",
    "        high_fractions,\n",
    "        low_fractions,\n",
    "    )\n",
    "    for loc_type, label in localization_labels.items()\n",
    "]\n",
    "\n",
    "# Create final table\n",
    "si_table_5 = pd.concat(protein_dataframes).rename(columns={0: \"tau_score\"})\n",
    "\n",
    "# Check names of low_tau_proteins (not defined), high_tau_score, etc.\n",
    "# Are you selecting for low or high tau?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SI Table 5\n",
    "\n",
    "# Load and process Brain RNA-Seq Data\n",
    "brain_rna_seq = map_hgnc_ids(hgnc_ids, brain_rna_seq_raw_path)\n",
    "expression_df = create_enrichment_dataframe(brain_rna_seq)\n",
    "\n",
    "# Group proteins by sub-cellular localization\n",
    "localization_types = [\"TMhelix\", \"internal\", \"external\"]\n",
    "localization_ids = {\n",
    "    loc: identify_localization(assays, loc, output_directory)\n",
    "    for loc in localization_types\n",
    "}\n",
    "\n",
    "# Calculate EV association scores for each sub-cellular localization category\n",
    "localization_results = []\n",
    "\n",
    "for loc, uniprot_ids in localization_ids.items():\n",
    "    proteins_with_fract = set(uniprot_ids) & set(fractionation_uniprot_ids)\n",
    "\n",
    "    fractionation_scores = [\n",
    "        find_ratio(tidy_data[protein], high_fractions, low_fractions)\n",
    "        for protein in proteins_with_fract\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"uniprot_ids\": list(proteins_with_fract),\n",
    "            \"ev_association_score\": fractionation_scores,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df = df.merge(hgnc_uniprot_mapping_data, on=\"uniprot_ids\")\n",
    "    df[\"localization\"] = loc\n",
    "\n",
    "    localization_results.append(df)\n",
    "\n",
    "# Concatenate dataframes\n",
    "fract_pattern = pd.concat(localization_results, ignore_index=True)\n",
    "\n",
    "# Calculate tau scores and filter by cutoff\n",
    "tau_score_cutoff = 0.75\n",
    "enrichment_values = expression_df.apply(\n",
    "    lambda row: calculate_enrichment(row, \"tau\"), axis=1\n",
    ")\n",
    "high_tau_score = enrichment_values[enrichment_values > tau_score_cutoff]\n",
    "\n",
    "filtered_expression_df = expression_df[\n",
    "    expression_df.index.isin(high_tau_score.index.tolist())\n",
    "]\n",
    "\n",
    "# Find proteins that are both specific to a cell type\n",
    "# and display the correct fractionation pattern. Label with cell type\n",
    "max_col_list = []\n",
    "uniprots_list = []\n",
    "\n",
    "for index, row in filtered_expression_df.iterrows():\n",
    "    max_column = row.idxmax()\n",
    "    max_col_list.append(max_column)\n",
    "    uniprots_list.append(index)\n",
    "\n",
    "cell_type_targets = pd.DataFrame(\n",
    "    {\"cell_type\": max_col_list, \"uniprot_id\": uniprots_list}\n",
    ")\n",
    "\n",
    "si_table_5 = fract_pattern.merge(\n",
    "    cell_type_targets, left_on=\"uniprot_ids\", right_on=\"uniprot_id\", how=\"inner\"\n",
    ")\n",
    "high_tau_score = high_tau_score.reset_index()\n",
    "si_table_5 = si_table_5.merge(high_tau_score, on=\"uniprot_ids\")\n",
    "\n",
    "# GTex Specificity to determine the extent to which the proteins are\n",
    "# specific to the brain on a body-wide level\n",
    "gtex_data = gtex_specificity(gtex_path)\n",
    "si_table_5 = si_table_5.merge(gtex_data, on=\"ensembl_gene_id\")\n",
    "\n",
    "si_table_5 = si_table_5.rename(columns={0: \"brain_tau_score\"})\n",
    "\n",
    "# this gives a runtime warning-- how do I fix this?\n",
    "\n",
    "# The runtime warning is from calculate_tau_score. This error usually\n",
    "# comes from dividing by zero. Is it possible that the max in the row\n",
    "# that is passed to calculate_enrichment is 0? If so, is this okay or\n",
    "# bad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the data for figure 1d and 1e\n",
    "\n",
    "# Filter data to include only SEC data collected\n",
    "# using a sample from a healthy individual\n",
    "tidy_data_sec = tidy_data[\n",
    "    (tidy_data.index.get_level_values(\"Health\") == \"Healthy\")\n",
    "    & (tidy_data.index.get_level_values(\"Sample\").str.contains(\"SEC\"))\n",
    "]\n",
    "\n",
    "# Extract SEC data for the pre-determined EV associated and contaminant proteins\n",
    "associated_proteins_df = extract_sample_npx(\n",
    "    [\"P08758\", \"P07355\", \"P09525\", \"Q9NP79\"], tidy_data_sec\n",
    ")\n",
    "contaminant_proteins_df = extract_sample_npx(\n",
    "    [\"P02751\", \"P00734\", \"P36955\", \"P01024\"], tidy_data_sec\n",
    ")\n",
    "\n",
    "associated_proteins = associated_proteins_df.pivot(columns=\"protein\", index=\"sample\")\n",
    "contaminant_proteins = contaminant_proteins_df.pivot(columns=\"protein\", index=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify targets found inside microglia cells that may be EV associated\n",
    "# using the raw data file\n",
    "\n",
    "identify_targets(\n",
    "    assay_list_path=assay_list_path,\n",
    "    uniprot_fasta_database=uniprot_fasta_database,\n",
    "    brain_rna_seq_raw_path=brain_rna_seq_raw_path,\n",
    "    region=\"internal\",\n",
    "    cell_type=\"microglia\",\n",
    "    specificity_metric=\"tau\",\n",
    "    specificity_cutoff=0.75,\n",
    "    high_fractions=high_fractions,\n",
    "    low_fractions=low_fractions,\n",
    "    sample_health=\"healthy\",\n",
    "    mean_median_individual=\"individual_median\",\n",
    "    raw_olink_data_file=raw_data,\n",
    "    plate_layout_dataframe=plate_layout_path,\n",
    "    output_directory=output_directory,\n",
    ")\n",
    "\n",
    "# You're passing a pathlib.Path filepath object (plate_layout_path) to\n",
    "# the identify_targets function as plate_layout_dataframe, which expects\n",
    "# a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify targets found inside microglia cells that may be EV associated using the tidy dataframe\n",
    "\n",
    "identify_targets(\n",
    "    assay_list_path=assay_list_path,\n",
    "    uniprot_fasta_database=uniprot_fasta_database,\n",
    "    brain_rna_seq_raw_path=brain_rna_seq_raw_path,\n",
    "    region=\"internal\",\n",
    "    cell_type=\"microglia\",\n",
    "    specificity_metric=\"tau\",\n",
    "    specificity_cutoff=0.75,\n",
    "    high_fractions=high_fractions,\n",
    "    low_fractions=low_fractions,\n",
    "    sample_health=\"healthy\",\n",
    "    mean_median_individual=\"individual_median\",\n",
    "    plate_layout_dataframe=plate_layout_path,\n",
    "    tidy_dataframe=tidy_data,\n",
    "    output_directory=output_directory,\n",
    ")\n",
    "\n",
    "# Duplicated from prior cell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a box-and-whisker plot for a target of interest\n",
    "\n",
    "plot_protein_fractionation(tidy_data, \"Q9Y251\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
